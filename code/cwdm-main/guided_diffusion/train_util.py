# code/cwdm-main/guided_diffusion/train_util.py

import functools
import os
import copy
import blobfile as bf
import torch as th
import torch.distributed as dist
from torch.optim import AdamW
import torch.cuda.amp as amp

from tqdm import tqdm

from . import dist_util, logger
from .resample import LossAwareSampler, UniformSampler
# â˜…â˜…â˜… ãƒ¢ãƒ‡ãƒ«ã®å¼•æ•°ã‚’è¾æ›¸ã«å¤‰æ›ã™ã‚‹ãŸã‚ã«å¿…è¦ãªé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â˜…â˜…â˜…
from .script_util import args_to_dict, model_and_diffusion_defaults
from DWT_IDWT.DWT_IDWT_layer import DWT_3D

class TrainLoop:
    def __init__(
        self,
        *,
        model,
        flow_matching, # ä»¥å‰ã®diffusionã‹ã‚‰å¤‰æ›´
        data,
        batch_size,
        microbatch,
        lr,
        ema_rate,
        log_interval,
        save_interval,
        resume_checkpoint,
        resume_step,
        use_fp16,
        fp16_scale_growth,
        schedule_sampler,
        weight_decay,
        lr_anneal_steps,
        dataset,      # train.pyã‹ã‚‰æ¸¡ã•ã‚Œã‚‹å¼•æ•°
        summary_writer,
        contr,
        args,         # â˜…â˜…â˜…ã€ä¿®æ­£ç‚¹1ã€‘args ã‚’å¼•æ•°ã«è¿½åŠ  â˜…â˜…â˜…
    ):
        self.model = model
        self.flow_matching = flow_matching # flow_matchingã‚’ä¿æŒ
        self.data = data
        self.iterdatal = iter(self.data)
        self.batch_size = batch_size
        self.microbatch = microbatch if microbatch > 0 else batch_size
        self.lr = lr
        self.ema_rate = (
            [ema_rate]
            if isinstance(ema_rate, float)
            else [float(x) for x in ema_rate.split(",")]
        )
        self.log_interval = log_interval
        self.save_interval = save_interval
        self.resume_checkpoint = resume_checkpoint
        self.use_fp16 = use_fp16
        self.fp16_scale_growth = fp16_scale_growth
        self.schedule_sampler = schedule_sampler or UniformSampler(flow_matching)
        self.weight_decay = weight_decay
        self.lr_anneal_steps = lr_anneal_steps
        self.args = args # â˜…â˜…â˜…ã€ä¿®æ­£ç‚¹2ã€‘self.args ã¨ã—ã¦å¼•æ•°ã‚’ä¿æŒ â˜…â˜…â˜…

        self.step = resume_step
        self.resume_step = resume_step
        self.global_batch = self.batch_size * dist.get_world_size()

        self.sync_cuda = th.cuda.is_available()
        self.device = dist_util.dev()

        self.dwt = DWT_3D("haar").to(self.device)

        self._load_and_sync_parameters()
        self.grad_scaler = amp.GradScaler(enabled=self.use_fp16)
        
        self.ema_params = [
            copy.deepcopy(list(self.model.parameters())) for _ in range(len(self.ema_rate))
        ]
        
        self.opt = AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã®å†é–‹å‡¦ç†
        if self.resume_step:
            self._load_optimizer_state()
            for rate, params in zip(self.ema_rate, self.ema_params):
                self._load_ema_parameters(rate)

    def _load_and_sync_parameters(self):
        # ã“ã®é–¢æ•°ã¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã®ã¿ã‚’èª­ã¿è¾¼ã‚€
        # å¼•æ•°ã¯èª­ã¿è¾¼ã¾ãªã„ãŸã‚ã€æ–°è¦å­¦ç¿’æ™‚ã¯ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒä½¿ã‚ã‚Œã‚‹
        resume_checkpoint = find_resume_checkpoint() or self.resume_checkpoint
        if resume_checkpoint:
            self.resume_step = parse_resume_step_from_filename(resume_checkpoint)
            if dist.get_rank() == 0:
                logger.log(f"loading model from checkpoint: {resume_checkpoint}...")
                # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ™‚ã¨ã¯ç•°ãªã‚Šã€å­¦ç¿’å†é–‹æ™‚ã¯é‡ã¿ã®ã¿ã‚’èª­ã¿è¾¼ã‚€
                # å¼•æ•°ãŒå¤‰ã‚ã£ã¦ã„ã‚‹å ´åˆã¯ã€æ–°ã—ã„æ§‹é€ ã®ãƒ¢ãƒ‡ãƒ«ã«èª­ã¿è¾¼ã‚‚ã†ã¨ã™ã‚‹
                self.model.load_state_dict(
                    dist_util.load_state_dict(
                        resume_checkpoint, map_location=self.device
                    )['model_state_dict'] # è¾æ›¸æ§‹é€ ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ã«å¤‰æ›´
                )
        dist_util.sync_params(self.model.parameters())

    def _load_ema_parameters(self, rate):
        # EMAã®å†é–‹ãƒ­ã‚¸ãƒƒã‚¯ (å¤‰æ›´ãªã—)
        # ...
        pass

    def _load_optimizer_state(self):
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®å†é–‹ãƒ­ã‚¸ãƒƒã‚¯ (å¤‰æ›´ãªã—)
        # ...
        pass
        
    def run_loop(self):
        # tqdmã‚’ä½¿ã£ãŸå­¦ç¿’ãƒ«ãƒ¼ãƒ— (å¤‰æ›´ãªã—)
        pbar = tqdm(range(self.lr_anneal_steps - self.step), initial=self.step, total=self.lr_anneal_steps, dynamic_ncols=True)
        for _ in pbar:
            try:
                # Flow-Matchingã§ã¯condã¯ä¸è¦ã‹ã‚‚ã—ã‚Œãªã„ãŒã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€æ§‹é€ ã‚’ç¶­æŒ
                batch, cond = next(self.iterdatal)
            except StopIteration:
                self.iterdatal = iter(self.data)
                batch, cond = next(self.iterdatal)
            
            self.run_step(batch, cond)
            
            if self.step % self.log_interval == 0:
                logger.dumpkvs()
            if self.step % self.save_interval == 0:
                self.save()
            
            self.step += 1
            if self.step >= self.lr_anneal_steps:
                break
        
        if (self.step - 1) % self.save_interval != 0:
            self.save()

    def run_step(self, batch, cond):
        self.forward_backward(batch, cond)
        self.grad_scaler.unscale_(self.opt)
        self.opt.step()
        self._update_ema()
        self.grad_scaler.update()
        self._anneal_lr()
        self.log_step()

    def forward_backward(self, batch, cond):
        """
        æœ€ã‚‚é‡è¦ãªå¤‰æ›´ç®‡æ‰€ã§ã™ã€‚
        ã“ã®é–¢æ•°å…¨ä½“ã‚’ä»¥ä¸‹ã®å†…å®¹ã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚
        """
        self.opt.zero_grad()
        for i in range(0, batch.shape[0], self.microbatch):
            # 1. ç”Ÿã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã®ãƒŸãƒ‹ãƒãƒƒãƒã‚’å–å¾—ã—ã¾ã™
            micro_batch_img = batch[i : i + self.microbatch].to(self.device)
            # æ¡ä»¶ç”»åƒã¯è¾æ›¸ã«å…¥ã£ã¦ã„ã‚‹ã®ã§ã€'cond_1'ã‚­ãƒ¼ã§ã‚¢ã‚¯ã‚»ã‚¹ã—ã¾ã™
            micro_cond_img = cond['cond_1'][i : i + self.microbatch].to(self.device)
            
            # 2. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨æ¡ä»¶ã®ä¸¡æ–¹ã‚’Waveletå¤‰æ›ã—ã¾ã™
            with th.no_grad():
                # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç”»åƒ (ä¾‹: t1c) -> Waveletä¿‚æ•°
                target_wav = th.cat(self.dwt(micro_batch_img), dim=1)
                # æ¡ä»¶ç”»åƒ (ä¾‹: t1n) -> Waveletä¿‚æ•°
                cond_wav = th.cat(self.dwt(micro_cond_img), dim=1)

            # 3. Flow-Matchingã®ãŸã‚ã«ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã™
            t, weights = self.schedule_sampler.sample(target_wav.shape[0], self.device)
            
            # ãƒ•ãƒ­ãƒ¼ã®å§‹ç‚¹: Waveletä¿‚æ•°ã¨åŒã˜å½¢çŠ¶ã®ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
            x_0_wav = th.randn_like(target_wav)
            # ãƒ•ãƒ­ãƒ¼ã®çµ‚ç‚¹: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®Waveletä¿‚æ•°
            x_1_wav = target_wav
            # ãƒ¢ãƒ‡ãƒ«ã¸ã®æ¡ä»¶: æ¡ä»¶ç”»åƒã®Waveletä¿‚æ•°
            model_kwargs_wav = {"cond_wav": cond_wav}

            # 4. æ­£ã—ã„Waveleté ˜åŸŸã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦æå¤±é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¾ã™
            compute_losses = functools.partial(
                self.flow_matching.training_losses,
                model=self.model,
                x_0=x_0_wav,
                x_1=x_1_wav,
                t=t,
                model_kwargs=model_kwargs_wav,
            )

            with amp.autocast(enabled=self.use_fp16):
                losses = compute_losses()

            loss = (losses["loss"] * weights).mean()
            log_loss_dict(
                self.flow_matching, t, {k: v.detach() for k, v in losses.items()}
            )
            self.grad_scaler.scale(loss).backward()

    def _update_ema(self):
        # ğŸ’¡ã€ã“ã“ãŒæœ€å¾Œã®ä¿®æ­£ç‚¹ã§ã™ã€‘ğŸ’¡
        # EMAã®æ›´æ–°å‡¦ç†å…¨ä½“ã‚’`with th.no_grad():`ã§å›²ã¿ã¾ã™ã€‚
        # ã“ã‚Œã«ã‚ˆã‚Šã€ã“ã®ãƒ–ãƒ­ãƒƒã‚¯å†…ã®è¨ˆç®—ã§ã¯å‹¾é…ãŒè¿½è·¡ã•ã‚Œãªããªã‚Šã€
        # in-placeæ“ä½œãŒå®‰å…¨ã«å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
        with th.no_grad():
            for rate, params in zip(self.ema_rate, self.ema_params):
                for p_main, p_ema in zip(self.model.parameters(), params):
                    p_ema.copy_(p_main.lerp(p_ema, rate))
        # --- âœ… ä¿®æ­£å®Œäº† âœ… ---

    def _anneal_lr(self):
        if not self.lr_anneal_steps:
            return
        frac_done = self.step / self.lr_anneal_steps
        lr = self.lr * (1 - frac_done)
        for param_group in self.opt.param_groups:
            param_group["lr"] = lr

    def log_step(self):
        logger.logkv("step", self.step)
        logger.logkv("samples", (self.step + 1) * self.global_batch)

    def save(self):
        """
        ãƒ¢ãƒ‡ãƒ«ã®å¼•æ•°ã€é‡ã¿ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®çŠ¶æ…‹ã€EMAã®é‡ã¿ã‚’ä¿å­˜ã™ã‚‹ã€‚
        """
        if dist.get_rank() != 0:
            return

        def _save_checkpoint(data, filename):
            """ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã§ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜"""
            with bf.BlobFile(bf.join(get_blob_logdir(), filename), "wb") as f:
                th.save(data, f)

        logger.log(f"saving model and optimizer state at step {self.step}...")

        # 1. ãƒ¡ã‚¤ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®çŠ¶æ…‹ã‚’ä¿å­˜
        model_args_dict = args_to_dict(self.args, model_and_diffusion_defaults().keys())
        save_data = {
            'model_args': model_args_dict,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.opt.state_dict(),
            'step': self.step,
            'args': self.args, # ãƒ‡ãƒãƒƒã‚°ã‚„å®Œå…¨ãªå†ç¾ã®ãŸã‚ã«å…¨å¼•æ•°ã‚‚ä¿å­˜
        }
        _save_checkpoint(save_data, f"model_{(self.step):06d}.pt")

        # 2. EMAãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä¿å­˜
        for rate, params in zip(self.ema_rate, self.ema_params):
            # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®state_dictã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€EMAãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ä¸Šæ›¸ã
            ema_state_dict = copy.deepcopy(self.model.state_dict())
            for name, p_ema in zip(ema_state_dict.keys(), params):
                # .data ã‚’ä½¿ã£ã¦ãƒ†ãƒ³ã‚½ãƒ«ã®å®Ÿä½“ã«ã‚¢ã‚¯ã‚»ã‚¹
                ema_state_dict[name].copy_(p_ema.data)
            
            # EMAãƒ¢ãƒ‡ãƒ«ã¯å¼•æ•°ã‚’æŒãŸãªã„ã®ã§ã€state_dictã®ã¿ã‚’ä¿å­˜
            _save_checkpoint(
                {"model_state_dict": ema_state_dict, "model_args": model_args_dict},
                f"ema_{rate}_{(self.step):06d}.pt"
            )
            
        logger.log("save complete.")
        dist.barrier() # ä»–ã®ãƒ—ãƒ­ã‚»ã‚¹ã¨åŒæœŸ

def log_loss_dict(process, ts, losses): # diffusionã‹ã‚‰processã«å¤‰æ›´
    for key, values in losses.items():
        logger.logkv_mean(key, values.mean().item())
        # The term 'num_timesteps' may not exist in FlowMatching.
        # Adjust if necessary.
        if hasattr(process, 'num_timesteps'):
            for sub_t, sub_loss in zip(ts.cpu().numpy(), values.detach().cpu().numpy()):
                quartile = int(4 * sub_t / process.num_timesteps)
                logger.logkv_mean(f"{key}_q{quartile}", sub_loss)

# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (å¤‰æ›´ãªã—)
def get_blob_logdir():
    return logger.get_dir()

def find_resume_checkpoint():
    return None

def parse_resume_step_from_filename(filename):
    split = os.path.basename(filename)
    split = split.split(".")[-2]
    split = split.split("_")[-1]
    reversed_split = []
    for c in reversed(split):
        if not c.isdigit():
            break
        reversed_split.append(c)
    split = ''.join(reversed(reversed_split))
    split = ''.join(c for c in split if c.isdigit())
    try:
        return int(split)
    except ValueError:
        return 0